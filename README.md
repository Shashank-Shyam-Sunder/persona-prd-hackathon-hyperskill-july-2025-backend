# PersonaPRD â€“ AI Hackathon July 2025 ğŸš€

PersonaPRD is an AI-powered system developed during the AI Hackathon July 2025. It transforms unstructured Reddit feedback into structured, persona-specific Product Requirements Documents (PRDs) using semantic embeddings, clustering, and Gemini-based summarization.

ğŸ¯ **The goal**: Accelerate early-stage product discovery and prioritization by extracting pain points directly from community conversations.

---

## ğŸ” What It Does

- Loads persona-aligned Reddit data from curated datasets.
- Cleans and embeds posts using SBERT (`all-MiniLM-L6-v2`).
- Saves a cleaned Excel snapshot with original + cleaned text for validation (`cleaned_posts.xlsx`).
- Clusters posts with UMAP + KMeans for topic grouping.
- Computes diagnostics like silhouette and intra/inter-cluster distance ratios.
- Generates interactive visualizations of clusters with Plotly.
- Summarizes each cluster into user pain points using Gemini (LangChain).
- Lets you select clusters to auto-generate a structured PRD (`.docx`).

---

## ğŸ—‚ï¸ Project Structure

```
persona-prd-hackathon-july-2025/
â”‚
â”œâ”€â”€ .venv/                               # Python virtual environment (optional)
â”œâ”€â”€ .env                                 # âš™ï¸ API credentials (GOOGLE_API_KEY)
â”œâ”€â”€ requirements.txt                     # ğŸ§° All Python dependencies
â”œâ”€â”€ LICENSE                              # ğŸ“œ Open-source license (MIT)
â”œâ”€â”€ README.md                            # You're reading it
â”‚
â”œâ”€â”€ run_full_mvp_cli.py                  # ğŸ” Main CLI to run entire pipeline (data loading to PRD generation)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ starter_datasets/
â”‚   â”‚       â”œâ”€â”€ data_neighbourhood/
â”‚   â”‚       â”œâ”€â”€ vibecoding_neighbourhood/
â”‚   â”‚       â””â”€â”€ selfhost_neighbourhood/
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ <persona>/<subreddit>/
â”‚           â”œâ”€â”€ cleaned_posts.xlsx
â”‚           â”œâ”€â”€ embeddings.npy
â”‚           â”œâ”€â”€ clusters_KMeans_UMAP.csv
â”‚           â”œâ”€â”€ cluster_diagnostics_metrics.csv
â”‚           â”œâ”€â”€ cluster_visualization.html
â”‚           â”œâ”€â”€ pain_point_summaries.csv
â”‚           â””â”€â”€ PRD_DRAFT_with_selected_pain_points.docx
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ embedding.py
â”‚   â”œâ”€â”€ clustering_KMeans_UMAP.py
â”‚   â”œâ”€â”€ cluster_diagnostics_module.py
â”‚   â”œâ”€â”€ cluster_visualization.py
â”‚   â”œâ”€â”€ summarization.py
â”‚   â”œâ”€â”€ prd_generator.py
â”‚   â”œâ”€â”€ persona_config.py
â”‚   â”œâ”€â”€ run_generate_prd.py
â”‚   â”œâ”€â”€ user_selection_utils.py
â”‚   â””â”€â”€ utils.py
â”‚
â”‚
â”œâ”€â”€ tests/                               # ğŸ§ª Unit tests for critical modules
â”‚   â”œâ”€â”€ test_cluster_numbering.py        # Ensures consistent cluster labels
â”‚   â”œâ”€â”€ test_imports.py                  # Checks if all imports work across files
â”‚   â”œâ”€â”€ test_requirements.py             # Verifies dependency alignment
â”‚   â”œâ”€â”€ test_user_selection.py           # Tests cluster selection logic
â”‚   â””â”€â”€ test_visualization.py            # Validates cluster visualization logic

```

---

## ğŸš€ Quickstart

1. ğŸ”§ **Install requirements**
```bash
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt
```

2. ğŸ”‘ **Set your Google API key**
Create a file named `.env` in the root:
```
GOOGLE_API_KEY=your-real-key-here
```

3. ğŸ§  **Run the full MVP pipeline**
```bash
python run_full_mvp_cli.py
```

You'll be prompted to:
- Select a persona
- Select a subreddit dataset
- Review pain point summaries
- Select which clusters to include in the PRD

---

## ğŸ“„ Output Files Explained

Each processed subreddit folder (`data/processed/<persona>/<subreddit>/`) contains:

- `cleaned_posts.xlsx` â€“ Original + cleaned post text (title, selftext, combined_text, cleaned_text)
- `embeddings.npy` â€“ SBERT-based embeddings (384-d)
- `clusters_KMeans_UMAP.csv` â€“ Mapping of `post_id` to cluster (labels range from 0â€“9 internally)
- `cluster_diagnostics_metrics.csv` â€“ Clustering quality metrics (silhouette, distances)
- `cluster_visualization.html` â€“ Interactive Plotly visualization (cluster labels shown as 1â€“10)
- `pain_point_summaries.csv` â€“ LLM-generated pain point summaries
- `PRD_DRAFT_with_selected_pain_points.docx` â€“ Final PRD document

---

## ğŸ§¾ Input JSON Format

Each dataset is a .json file containing an array of Reddit posts, where each post includes:

- **Post metadata**: `id`, `title`, `selftext`, `url`, `score`, `upvote_ratio`, `num_comments`, `created_utc`, `author`, `subreddit`
- **Post flags**: e.g., `is_self`, `stickied`, `locked`, `spoiler`, etc.
- **Comment threads (up to 100)**: Nested objects with `id`, `body`, `score`, `created_utc`, `author`, and parent relationships
- **Engagement metrics**: Vote scores, comment counts, interaction ratios

ğŸ“Œ **Current Scope in MVP**:  
We currently use only the post title and selftext for our semantic analysis. These are combined into a single string (`combined_text`) per post to generate embeddings.

---

## ğŸ§¾ Clustering Diagnostics: Interpretation Guide

<details>
<summary><strong>Interpretation Guide (Click to expand)</strong></summary>

<br>

| Metric                    | What It Means                                                                 | Good Range                   | Interpretation                                                                 |
|---------------------------|-------------------------------------------------------------------------------|------------------------------|---------------------------------------------------------------------------------|
| **Silhouette Score**      | How well points fit their clusters vs. others                                 | > 0.5 (Good), > 0.2 (Moderate) | Higher means well-separated, dense clusters. Negative or near 0 is bad.        |
| **Intra-cluster Distance**| Avg. distance from points to their own cluster centroid (compactness)         | < 0.5 (Tight), < 0.8 (OK)     | Lower = denser clusters. High = clusters are loose or incoherent.              |
| **Inter-cluster Distance**| Avg. distance between cluster centroids (separation)                          | > 1.0 (Good), > 0.6 (OK)      | Higher = clusters are well-separated in space.                                 |
| **Intra/Inter Ratio**     | Intra-cluster distance Ã· Inter-cluster distance                               | < 1.0 (Ideal), < 1.2 (Good)   | Lower = clusters are compact and well-separated. > 1.5 usually means weak results. |

</details>
---

## ğŸ” Notes for Users to interpret clustering metrics 

- âœ… **Use these metrics comparatively** â€” they are best for comparing multiple runs (e.g., UMAP vs no UMAP).
- âš ï¸ A *low Silhouette Score* doesn't always mean bad clustering â€” especially if your goal is diversity or coverage.
- ğŸ§  Always **visualize clusters** and **inspect actual content** for final decisions. You may see the interactive plotly plot for each subreddit processed data in the file `cluster_visualization.html`.

---


## ğŸ§ª Running Tests

This project includes a minimal test suite to validate core functionality across modules.

To run all tests:

```bash
pytest tests/
```

Make sure your virtual environment is activated and dependencies are installed (`pip install -r requirements.txt`).

Please note: All tests should pass, though you may see warnings if some test functions return True/False instead of using assert statements. This does not affect the outcome but can be improved for better practice.

### âœ… What's Covered

| Test File                     | Purpose                                                       |
|------------------------------|---------------------------------------------------------------|
| `test_cluster_numbering.py`  | Ensures consistent and gap-free cluster labeling              |
| `test_imports.py`            | Verifies all key modules can be imported correctly            |
| `test_requirements.py`       | Confirms required packages are installed and version-matched  |
| `test_user_selection.py`     | Tests CLI-based user cluster selection logic                  |
| `test_visualization.py`      | Validates cluster visualization rendering (Plotly HTML output)|

Tests are designed to be fast and run without requiring internet access or real API keys.

---

## âš ï¸ Important Notes & Developer Tips

### 1. ğŸ’¥ Changing LLM or Embedding Model?
If you change either:
- The **embedding model** in `embedding.py`, or
- The **LLM model** in `summarization.py`

ğŸ‘‰ **Delete or back up** the corresponding folder under `data/processed/` so fresh embeddings, clusters, summaries, and PRD are regenerated.

### 2. ğŸ“ Relative Imports & Testing
The code in `src/` uses **relative paths**. If you try to run a module like `src/pipeline.py` directly, youâ€™ll get import errors.  
âœ… Use the `run_full_mvp_cli.py` script at the root level to run the full pipeline.

To test individual files directly, add this to the top of the file:
```python
import sys
import os
sys.path.append(os.path.abspath(".."))
```

### 3. ğŸ”¢ Cluster Label Conventions
- Internally saved cluster labels (in `.csv`) are from `0â€“9`.
- For display in CLI and Plotly plots, they are **converted to 1â€“10** for human readability.

### 4. ğŸ” Switch to a Different LLM or Embedding?
Update the following files:
- **LLM summarization** â†’ `src/summarization.py` and `src/prd_generator.py`
- **Embedding model** â†’ `src/embedding.py`

### 5. ğŸ” .env Setup Reminder
Before running the code, create a `.env` file and paste your Google API key:
```
GOOGLE_API_KEY=your-real-key-here
```
ğŸ’¡ You can switch to GPT-4, Claude, or other providers with minor adjustments.

### 6. ğŸ†” Why `post_id`?
The original Reddit JSON contains a field called `id`.  
We **rename it to `post_id`** in preprocessing to improve clarity and ensure consistent referencing across files (clustering, summaries, PRD).

---

## ğŸ”¬ Model Configuration

- **Embeddings**: `sentence-transformers/all-MiniLM-L6-v2`
- **LLM Summarization**: `Gemini 1.5 Flash` (via LangChain)
- Both can be swapped based on preferences and quota availability.

---

## ğŸ’¡ Ideal Use Cases

- Product Managers and Designers doing early-stage user discovery
- AI teams building semantic feedback clustering tools
- Startups validating ideas using community pain points
- UX Researchers summarizing feedback at scale
- AI Engineers building LLM-based research or discovery pipelines

---

## ğŸ§  Credits

Built by Team Clouded Sky (Hackathon team name) as part of the Hyperskill AI Engineer Bootcamp + Hackathon (July 2025).

## ğŸ“œ License

MIT License â€” feel free to fork, use, and build on top of this project.
